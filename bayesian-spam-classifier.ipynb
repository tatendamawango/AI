{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_folder = 'spam'\n",
    "testing_spam_folder = 'Testing_data\\spam'\n",
    "training_spam_folder = 'Training_data\\spam'\n",
    "\n",
    "os.makedirs(testing_spam_folder, exist_ok=True)\n",
    "os.makedirs(training_spam_folder, exist_ok=True)\n",
    "\n",
    "spam_files = os.listdir(spam_folder)\n",
    "\n",
    "random.shuffle(spam_files)\n",
    "\n",
    "num_files = len(spam_files)\n",
    "num_testing_files = int(num_files * 0.3)\n",
    "\n",
    "for i, file in enumerate(spam_files):\n",
    "    src_path = os.path.join(spam_folder, file)\n",
    "    \n",
    "    if i < num_testing_files:\n",
    "        dest_path = os.path.join(testing_spam_folder, file)\n",
    "    else:\n",
    "        dest_path = os.path.join(training_spam_folder, file)\n",
    "    \n",
    "    shutil.copy(src_path, dest_path)\n",
    "\n",
    "\n",
    "ham_folder = 'ham'\n",
    "testing_ham_folder = 'Testing_data\\ham'\n",
    "training_ham_folder = 'Training_data\\ham'\n",
    "\n",
    "os.makedirs(testing_ham_folder, exist_ok=True)\n",
    "os.makedirs(training_ham_folder, exist_ok=True)\n",
    "\n",
    "ham_files = os.listdir(ham_folder)\n",
    "\n",
    "random.shuffle(ham_files)\n",
    "\n",
    "num_files = len(ham_files)\n",
    "num_testing_files = int(num_files * 0.3)\n",
    "\n",
    "for i, file in enumerate(ham_files):\n",
    "    src_path = os.path.join(ham_folder, file)\n",
    "    \n",
    "    if i < num_testing_files:\n",
    "        dest_path = os.path.join(testing_ham_folder, file)\n",
    "    else:\n",
    "        dest_path = os.path.join(training_ham_folder, file)\n",
    "    \n",
    "    shutil.copy(src_path, dest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam = 'spam'\n",
    "ham = 'ham'\n",
    "spam_training_path = 'Training_data\\spam'\n",
    "ham_training_path = 'Training_data\\ham'\n",
    "spam_testing_path = 'Testing_data\\spam'\n",
    "ham_testing_path = 'Testing_data\\ham'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(file_path):\n",
    "    with open(file_path, 'r', encoding='latin-1') as file:\n",
    "        content = file.read()\n",
    "        words = re.findall(r'\\b\\w[\\w!@$&]*\\b', content)\n",
    "    return words\n",
    "\n",
    "def get_words_from_files(folder_path):\n",
    "    words_list = []\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        words_list.extend(get_words(file_path))\n",
    "    return words_list\n",
    "\n",
    "def calculate_spamicity(word_counts, total_spam_words, total_ham_words):\n",
    "    spamicity_list = []\n",
    "    for word, counts in word_counts.items():\n",
    "        p_spam_word = counts['spam'] / total_spam_words\n",
    "        p_ham_word = counts['ham'] / total_ham_words\n",
    "        spamicity = p_spam_word / (p_spam_word + p_ham_word)\n",
    "        spamicity_list.append([word, counts['spam'], counts['ham'], spamicity])\n",
    "    return spamicity_list\n",
    "\n",
    "def save_spamicity_to_csv(spamicity_list, file_path):\n",
    "    df = pd.DataFrame(spamicity_list, columns=['Word', 'Spam Count', 'Ham Count', 'Spamicity'])\n",
    "    df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(spam_path, ham_path, type):\n",
    "    print(f\"{' '*30}{'*'*20}{type} data{'*'*20}\\n\\n\")\n",
    "\n",
    "    spam_words = get_words_from_files(spam_path)\n",
    "    ham_words = get_words_from_files(ham_path)\n",
    "\n",
    "    num_spam_files = len(os.listdir(spam_path))\n",
    "    num_ham_files = len(os.listdir(ham_path))\n",
    "\n",
    "    print(f\"Number of SPAM files: {num_spam_files}\")\n",
    "    print(f\"Number of HAM files: {num_ham_files}\")\n",
    "\n",
    "    total_spam_words = len(spam_words)\n",
    "    total_ham_words = len(ham_words)\n",
    "\n",
    "    print('Total spam words:', total_spam_words)\n",
    "    print('Total ham words:', total_ham_words)\n",
    "\n",
    "    word_counts = defaultdict(lambda: {'spam': 0, 'ham': 0})\n",
    "    for word in spam_words:\n",
    "        word_counts[word]['spam'] += 1\n",
    "    for word in ham_words:\n",
    "        word_counts[word]['ham'] += 1\n",
    "\n",
    "\n",
    "    csv_name = f'{type}_spamicity.csv'\n",
    "    spamicity_list = calculate_spamicity(word_counts, total_spam_words, total_ham_words)\n",
    "    save_spamicity_to_csv(spamicity_list, csv_name)\n",
    "\n",
    "    spamicity_df = pd.read_csv(csv_name)\n",
    "\n",
    "    print('Spamicity calculation completed.')\n",
    "\n",
    "    print(\"Total number of spam words:\", total_spam_words)\n",
    "    print(\"Total number of ham words:\", total_ham_words)\n",
    "\n",
    "\n",
    "    new_file = 'Earn m0ney zzz.'\n",
    "    filename = 'new_file.txt'\n",
    "    with open(filename, 'w', encoding='latin-1') as f:\n",
    "        f.write(new_file)\n",
    "\n",
    "    new_file_path = 'new_file.txt'\n",
    "    new_words = get_words(new_file_path)\n",
    "    new_words_spamicity = spamicity_df.loc[spamicity_df['Word'].isin(new_words), 'Spamicity']\n",
    "\n",
    "    # print(\"\\nSpamicity values for new words:\")\n",
    "    # print(new_words_spamicity)\n",
    "\n",
    "    N = [8,16, 32]\n",
    "\n",
    "    for n in N:\n",
    "        closest_to_mean = (new_words_spamicity - new_words_spamicity.mean()).abs().nsmallest(n)\n",
    "        selected_spamicity = new_words_spamicity.loc[closest_to_mean.index]\n",
    "        p = np.prod(selected_spamicity)\n",
    "        pc = np.prod(1 - selected_spamicity)\n",
    "        spamicity = p / (p + pc)\n",
    "\n",
    "        print(\"\\nN:\", n)\n",
    "        print(\"Spamicity of the new file:\", spamicity)\n",
    "        print(\"Is the new file spam?\", \"Yes\" if spamicity > 0.5 else \"No\")\n",
    "\n",
    "    def plot_spamicity(spamicity_df, word=\"\"):\n",
    "        plt.title(f'Spamicity plot')\n",
    "        plt.xlabel('Spamicity')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.hist(spamicity_df['Spamicity'], bins=30, color='blue', edgecolor='black')\n",
    "        plt.show()\n",
    "\n",
    "    plot_spamicity(spamicity_df, 'earn')\n",
    "\n",
    "    def plot_spam_ham_counts(spamicity_df, n):\n",
    "        top_n_words = spamicity_df.sort_values(by='Spam Count', ascending=False).head(n)['Word']\n",
    "        top_n_words_spamicity = spamicity_df.loc[spamicity_df['Word'].isin(top_n_words), ['Word', 'Spam Count', 'Ham Count']]\n",
    "        top_n_words_spamicity.set_index('Word', inplace=True)\n",
    "        top_n_words_spamicity.plot.bar()\n",
    "        plt.title(f'Spam and Ham counts for top {n} words')\n",
    "        plt.xlabel('Word')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.show()\n",
    "    \n",
    "    plot_spam_ham_counts(spamicity_df, 10)\n",
    "\n",
    "    def classify(filepath, spamicity_df, N):\n",
    "        ss = spamicity_df.loc[spamicity_df['Word'].isin(get_words(filepath)), 'Spamicity'].nsmallest(N)\n",
    "        return np.prod(ss) / (np.prod(1 - ss) + np.prod(ss)) > 0.5\n",
    "\n",
    "\n",
    "    def test(spam_path, ham_path, spamicity_df, N):\n",
    "        num_spam_correct = []\n",
    "        num_ham_correct = []\n",
    "\n",
    "\n",
    "        for filename in os.listdir(spam_path):\n",
    "            filepath = os.path.join(spam_path, filename)\n",
    "            isp = classify(filepath, spamicity_df, N)\n",
    "            num_spam_correct.append(isp)\n",
    "            num_ham_correct.append(True)\n",
    "\n",
    "        for filename in os.listdir(ham_path):\n",
    "            filepath = os.path.join(ham_path, filename)\n",
    "            ish = classify(filepath, spamicity_df, N)\n",
    "            num_ham_correct.append(ish)\n",
    "            num_spam_correct.append(False)\n",
    "\n",
    "\n",
    "        num_spam_correct = np.array(num_spam_correct)\n",
    "        num_ham_correct = np.array(num_ham_correct)\n",
    "\n",
    "        false_positive = np.sum((num_spam_correct == True)&(num_ham_correct == False))\n",
    "        false_negative = (N-np.sum((num_spam_correct == False)|(num_ham_correct == True)))*2\n",
    "        accuracy = 1 - accuracy_score(num_ham_correct, num_spam_correct)\n",
    "\n",
    "        print(f'False positive: {false_positive}')\n",
    "        print(f'False negative: {false_negative}')\n",
    "        print(f'Accuracy: {accuracy}')\n",
    "\n",
    "    \n",
    "    test(spam_testing_path, ham_testing_path, spamicity_df, 8)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(spam_training_path, ham_training_path, 'training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(spam_testing_path, ham_testing_path, 'testing')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
